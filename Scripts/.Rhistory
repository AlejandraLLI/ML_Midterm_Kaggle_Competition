train<-read.csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/train.csv',header=TRUE)
head(train)
head(train[1:10,1:10])
256*256
head(train[(nrow-10):nrow,(ncol-10):ncol()])
head(train[(nrow-10):nrow,(ncol-10):ncol])
head(train[(nrow(train)-10):nrow(train),(ncol(train)-10):ncol(train)])
dim(train)
tail(train[,(ncol(train)-10):ncol(train)])
#---- Cargamos paquetes----
# install.packages("tidyverse")
# install.packages("data.table")
# install.packages("glmnet")
library(tidyverse)
library(data.table)
library(glmnet)
#---- Leemos los datos de entrenamiento ----
train<-read_csv('train.csv')
train2<-train
# train <- train %>%
#   mutate(estado=ifelse(estado=='abierto',1,0),hour= hour(hora), minutes= minute(hora))%>%
#   select(-hora)
train <- train %>%
mutate(estado=ifelse(estado=='abierto',1,0),
hour= hour(hora),
minutes= minute(hora)) %>%
select(-hora)
train<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datostrain.csv')
library(tidyverse)
library(data.table)
library(glmnet)
train<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/train.csv')
train<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/train.csv')
# Cargamos la base de datos
load(iris)
head(iris)
head(iris)
library(tidyverse)
head(iris)
iris_tidy<-iris%>% gather(Variable,Medida,-Species)
# Apilamos las columnas.
iris_tidy<-iris %>%
gather(Variable, Medida, -Species)%>%
# Mostramos los primeros renglones de la base limpia.
head(iris_tidy)
# Apilamos las columnas.
iris_tidy<-iris %>%
gather(Variable, Medida, -Species)
# Mostramos los primeros renglones de la base limpia.
head(iris_tidy)
# Apilamos las columnas.
iris_tidy<-iris %>%
gather(Variable, Medida, -Species) %>%
mutate(Parte=substring(Variable,1,5), Medida=substring(Variable,7)) %>%
select(-Variable)
# Mostramos los primeros renglones de la base limpia.
head(iris_tidy)
# Apilamos las columnas.
iris_tidy<-iris %>%
gather(Variable, Valor, -Species) %>%
mutate(Parte=substring(Variable,1,5), Medida=substring(Variable,7)) %>%
select(-Variable)
# Mostramos los primeros renglones de la base limpia.
head(iris_tidy)
# Apilamos las columnas.
iris_tidy<-iris %>%
gather(Variable, Valor, -Species) %>%
mutate(Parte=substring(Variable,1,5), Medida=substring(Variable,7)) %>%
select(Species,Parte, Medida, Valor)
# Mostramos los primeros renglones de la base limpia.
head(iris_tidy)
dim(iris_tidy)
str(iris_tidy)
head(iris)
#---- Cargamos paquetes----
# install.packages("tidyverse")
# install.packages("data.table")
# install.packages("glmnet")
library(tidyverse)
library(data.table)
library(glmnet)
library(keras)
#---- Leemos los datos de entrenamiento ----
entrena<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/train.csv')
entrena2<-entrena
entrena <- entrena %>%
mutate(estado=ifelse(estado=='abierta',1,0),
hour= hour(hora),
minutes= minute(hora),
hora=as.numeric(hora))
#---- Dividimos en muestra de entrenamiento y de validación ----
# Seleccionamos el porcentaje de datos que formarán parte de los datos de entrenamiento y de validación.
fractionTraining <- 0.75
fractionValidation <- 0.25
# Obtenemos el tamaño de muestra de las fracciones anteriores.
sampleSizeTraining <- floor(fractionTraining * nrow(entrena))
sampleSizeValidation <- floor(fractionValidation * nrow(entrena))
#Creamos los índices aleatoriamente.
set.seed(584852)
indicesTraining <- sort(sample(seq_len(nrow(entrena)), size=sampleSizeTraining))
#Creamos los dataframes de entrenamiento y validación a partir de lo anterior.
train   <- entrena[indicesTraining, ]
validation <- entrena[-indicesTraining, ]
#---- Leemos los datos de prueba ----
test<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/test.csv')
test2<-test
test <- test %>%
mutate(hour= hour(hora),
minutes= minute(hora),
hora=as.numeric(hora))
colnames(train)[38000:ncol(train)]
head(train[,38000:ncol(train)])
ncol(train)
x_mod20<-as.matrix(train[,c(1:38000,38002)])
mod20<-cv.glmnet(x=x_mod20,y=train$estado,
alpha=1,
family='binomial',
intercept=FALSE,
parallel=TRUE,
nfolds=10,
lambda=exp(seq(-12,2,1)))
plot(mod20)
proba_entrena_mod20<-predict(mod20,newx=x_mod20,s='lambda.1se',type="response")
estado_estim_train_mod20<-ifelse(proba_entrena_mod20>0.5,1,0)
dev_cv_mod20<-mod20$cvm[mod20$lambda==mod20$lambda.1se]
dev_cv_mod20
table(proba_entrena_mod20>0.5,train$estado)
prop.tale(table(proba_entrena_mod20>0.5,train$estado),2)
prop.table(table(proba_entrena_mod20>0.5,train$estado),2)
x_prueba_mod20<-as.matrix(test)
proba_prueba_mod20<-predict(mod20,newx=x_prueba_mod20,s='lambda.1se',type="response")
dim(x_prueba_mod20)
dim(x_mod20)
colnames(test)[38000:ncol(test)]
x_prueba_mod20<-as.matrix(test[,1:38001])
proba_prueba_mod20<-predict(mod20,newx=x_prueba_mod20,s='lambda.1se',type="response")
estado_estim_prueba_mod20<-ifelse(proba_prueba_mod20>0.5,1,0)
write.csv(proba_prueba_mod20,"Result_prueba_mod20.csv")
getwd()
setwd("E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Scripts")
write.csv(proba_prueba_mod20,"~/Resultados/Result_prueba_mod20_test.csv")
setwd("E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Scripts")
getwd()
write.csv(proba_prueba_mod20,"~/Resultados/Result_prueba_mod20_test.csv")
write.csv(proba_prueba_mod20,"E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Resultados/Result_prueba_mod20_test.csv")
table(proba_entrena_mod20>0.5,train$estado)
prop.table(table(proba_entrena_mod20>0.5,train$estado),2)
dev_cv_mod20
setwd("E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Scripts")
#---- Cargamos paquetes----
# install.packages("tidyverse")
# install.packages("data.table")
# install.packages("glmnet")
library(tidyverse)
library(data.table)
library(glmnet)
library(keras)
#---- Leemos los datos de entrenamiento ----
entrena<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/train.csv')
entrena2<-entrena
entrena <- entrena %>%
mutate(estado=ifelse(estado=='abierta',0,1),
hour= hour(hora),
minutes= minute(hora),
hora=as.numeric(hora))
#---- Dividimos en muestra de entrenamiento y de validación ----
# Seleccionamos el porcentaje de datos que formarán parte de los datos de entrenamiento y de validación.
fractionTraining <- 0.75
fractionValidation <- 0.25
# Obtenemos el tamaño de muestra de las fracciones anteriores.
sampleSizeTraining <- floor(fractionTraining * nrow(entrena))
sampleSizeValidation <- floor(fractionValidation * nrow(entrena))
#Creamos los índices aleatoriamente.
set.seed(584852)
indicesTraining <- sort(sample(seq_len(nrow(entrena)), size=sampleSizeTraining))
#Creamos los dataframes de entrenamiento y validación a partir de lo anterior.
train   <- entrena[indicesTraining, ]
validation <- entrena[-indicesTraining, ]
#---- Leemos los datos de prueba ----
test<-read_csv('E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/datos/test.csv')
test2<-test
test <- test %>%
mutate(hour= hour(hora),
minutes= minute(hora),
hora=as.numeric(hora))
#---- Mod20 LASSO con la fecha completa (sin hora y minutos)----
# Extraemos las enradas
set.seed(12345)
x_mod20<-as.matrix(train[,c(1:38000,38002)])
# Corremos un modelo glm.
mod20<-cv.glmnet(x=x_mod20,y=train$estado,
alpha=1,
family='binomial',
intercept=FALSE,
parallel=TRUE,
nfolds=10,
lambda=exp(seq(-12,2,1)))
plot(mod20)
# Error Entrenamiento y Clasificación Entrenamiento
# Obtenemos las probabilidades de clase
proba_entrena_mod20<-predict(mod20,newx=x_mod20,s='lambda.1se',type="response")
# Obtenemos la clasificación de entrenamiento
estado_estim_train_mod20<-ifelse(proba_entrena_mod20>0.5,1,0)
# Obtenemos la devianza del cv.
dev_cv_mod20<-mod20$cvm[mod20$lambda==mod20$lambda.1se]
# Obtenemos la matriz de confusión de entrenamiento
table(proba_entrena_mod20>0.5,train$estado)
prop.table(table(proba_entrena_mod20>0.5,train$estado),2)
# Error Prueba y Clasificador Prueba
# Obtenemos las probabilidades de clase para el conjunto de prueba
x_prueba_mod20<-as.matrix(test[,1:38001])
proba_prueba_mod20<-predict(mod20,newx=x_prueba_mod20,s='lambda.1se',type="response")
# Obtenemos la clasificación de prueba
estado_estim_prueba_mod20<-ifelse(proba_prueba_mod20>0.5,1,0)
# Exportamos los resultados del modelo 3.
write.csv(proba_prueba_mod20,"E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Resultados/Result_prueba_mod20_test.csv")
table(proba_entrena_mod20>0.5,train$estado)
prop.table(table(proba_entrena_mod20>0.5,train$estado),2)
proba_prueba_mod20<
proba_prueba_mod20
#---- Mod21 RIDGE sin estandarizar, con la fecha completa (sin hora y minutos)----
# Extraemos las enradas
set.seed(12345)
x_mod21<-as.matrix(train[,c(1:38000,38002)])
# Corremos un modelo glm.
mod21<-cv.glmnet(x=x_mod21,y=train$estado,
alpha=0,
family='binomial',
intercept=FALSE,
parallel=TRUE,
nfolds=10,
lambda=exp(seq(-12,2,1)))
plot(mod21)
# Error Entrenamiento y Clasificación Entrenamiento
# Obtenemos las probabilidades de clase
proba_entrena_mod21<-predict(mod21,newx=x_mod21,s='lambda.1se',type="response")
# Obtenemos la clasificación de entrenamiento
estado_estim_train_mod21<-ifelse(proba_entrena_mod21>0.5,1,0)
# Obtenemos la devianza del cv.
dev_cv_mod21<-mod21$cvm[mod21$lambda==mod21$lambda.1se]
# Obtenemos la matriz de confusión de entrenamiento
table(proba_entrena_mod21>0.5,train$estado)
prop.table(table(proba_entrena_mod21>0.5,train$estado),2)
# Error Prueba y Clasificador Prueba
# Obtenemos las probabilidades de clase para el conjunto de prueba
x_prueba_mod21<-as.matrix(test[,1:38001])
proba_prueba_mod21<-predict(mod21,newx=x_prueba_mod21,s='lambda.1se',type="response")
# Obtenemos la clasificación de prueba
estado_estim_prueba_mod21<-ifelse(proba_prueba_mod21>0.5,1,0)
# Exportamos los resultados del modelo 3.
write.csv(proba_prueba_mod21,"E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Resultados/Result_prueba_mod21_test.csv")
dev_cv_mod20
dev_cv_mod21
table(proba_entrena_mod20>0.5,train$estado)
prop.table(table(proba_entrena_mod20>0.5,train$estado),2)
table(proba_entrena_mod21>0.5,train$estado)
prop.table(table(proba_entrena_mod21>0.5,train$estado),2)
dev_cv_mod21
dev_cv_mod20
colnames(train)[38000:col(train)]
colnames(train)[38000:ncol(train)]
train<-enrena
train<-entrena
x_train_norm<-scale(train[c(1:38000,38002)])
x_train_norm
attr(x_train_norm,"scaled:center")
#---- Mod20 LASSO sin estandarizar, con la fecha completa (sin hora y minutos)----
# Extraemos las enradas
set.seed(12345)
x_mod20<-as.matrix(train[,c(1:38000,38002)])
# Corremos un modelo glm.
mod20<-cv.glmnet(x=x_mod20,y=train$estado,
alpha=1,
family='binomial',
intercept=FALSE,
parallel=TRUE,
nfolds=10,
lambda=exp(seq(-12,2,1)))
plot(mod20)
# Error Entrenamiento y Clasificación Entrenamiento
# Obtenemos las probabilidades de clase
proba_entrena_mod20<-predict(mod20,newx=x_mod20,s='lambda.1se',type="response")
# Obtenemos la clasificación de entrenamiento
estado_estim_train_mod20<-ifelse(proba_entrena_mod20>0.5,1,0)
# Obtenemos la devianza del cv.
dev_cv_mod20<-mod20$cvm[mod20$lambda==mod20$lambda.1se]
# Obtenemos la matriz de confusión de entrenamiento
table(proba_entrena_mod20>0.5,train$estado)
prop.table(table(proba_entrena_mod20>0.5,train$estado),2)
# Error Prueba y Clasificador Prueba
# Obtenemos las probabilidades de clase para el conjunto de prueba
x_prueba_mod20<-as.matrix(test[,1:38001])
proba_prueba_mod20<-predict(mod20,newx=x_prueba_mod20,s='lambda.1se',type="response")
# Obtenemos la clasificación de prueba
estado_estim_prueba_mod20<-ifelse(proba_prueba_mod20>0.5,1,0)
# Exportamos los resultados del modelo 3.
write.csv(proba_prueba_mod20,"E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Resultados/Result_prueba_mod20_test.csv")
#---- Mod21 RIDGE sin estandarizar, con la fecha completa (sin hora y minutos)----
# Extraemos las enradas
set.seed(12345)
x_mod21<-as.matrix(train[,c(1:38000,38002)])
# Corremos un modelo glm.
mod21<-cv.glmnet(x=x_mod21,y=train$estado,
alpha=0,
family='binomial',
intercept=FALSE,
parallel=TRUE,
nfolds=10,
lambda=exp(seq(-12,2,1)))
plot(mod21)
# Error Entrenamiento y Clasificación Entrenamiento
# Obtenemos las probabilidades de clase
proba_entrena_mod21<-predict(mod21,newx=x_mod21,s='lambda.1se',type="response")
# Obtenemos la clasificación de entrenamiento
estado_estim_train_mod21<-ifelse(proba_entrena_mod21>0.5,1,0)
# Obtenemos la devianza del cv.
dev_cv_mod21<-mod21$cvm[mod21$lambda==mod21$lambda.1se]
# Obtenemos la matriz de confusión de entrenamiento
table(proba_entrena_mod21>0.5,train$estado)
prop.table(table(proba_entrena_mod21>0.5,train$estado),2)
# Error Prueba y Clasificador Prueba
# Obtenemos las probabilidades de clase para el conjunto de prueba
x_prueba_mod21<-as.matrix(test[,1:38001])
proba_prueba_mod21<-predict(mod21,newx=x_prueba_mod21,s='lambda.1se',type="response")
# Obtenemos la clasificación de prueba
estado_estim_prueba_mod21<-ifelse(proba_prueba_mod21>0.5,1,0)
# Exportamos los resultados del modelo 3.
write.csv(proba_prueba_mod21,"E:/ITAM Maestría/Otoño 2017/Aprendizaje de Máquina/ExamenParcial/Resultados/Result_prueba_mod21_test.csv")
dev_cv_mod20
dev_cv_mod21
